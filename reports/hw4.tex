\documentclass[10pt]{article}
\usepackage{latexsym}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}

\title{Homework 4: Project-Related Paper Report}
\author{Yu Feng}
\date{4/20/2015}

\begin{document}
\maketitle

\section{Summary}\label{sec:intro}
Using natural language to write programs is a challenging problem for both NLP 
and PL communities. SmartSynth~\cite{smart} tackles this problem in a small domain of mobile computing. Specifically, it synthesizes smartphone automation scripts from natural language. For instance, when the user fires a task in natural language 
like the following:
\begin{quotation}
``When I receive a new SMS and I am driving, reply the sender ``I'm driving."."
\end{quotation}
the system will generate the following executable script:
\small\begin{verbatim}
when (number, content) := MessageReceived()
    if (IsConnectedToBTDevice(Car_BT) then
        SendMessage(number, "I'm driving");
\end{verbatim}
To achieve the above goal, SmartSynth's approach incorporates two key ingredients: First, it designs
a domain specific language(DSL) to bridge the gap between natural language and the
target script; Second, it infers a set of components and their partial dataflow relations 
from natural language using NLP techniques; Third, for the missing dataflow relations that can not 
be detected by previous step, SmartSynth infers them via type-based synthesis~\citep{typebase}, 
a standard technique from the program synthesis community.

Here is the entire workflow of the system: given a task from the user, 
SmartSynth first maps the natural language into script components such as
APIs(SendMessage) and literals(``I'm driving"); Then it uses some light-weight NLP techniques
to uncover the dataflow relations between components(``I'm driving" is an argument of SendMessage),
such as Named-entity recognition and POS tagging; If previous dataflow relations do not fully specify
the dataflow relationships, SmartSynth invokes a type-based synthesis algorithm to complete the 
missing relations; Finally, if there are multiple equally high-ranked relations, the system will
trigger an interactive conversation with the user to resolve ambiguity.

The most interesting features of SmartSynth is inferring the dataflow relations between
components: although its NLP algorithm can map the feature set into target components,
it might not precisely capture all the cases due to the ambiguity of natural language.
In this case, SmartSynth incorporates techniques from program synthesis to increase
the confidence about the quality of target script.

SmartSynth's corpus is very small: it compiles 50 online task descriptions found in
help forums of Tasker, App Inventor and TouchDevelop. The overall result
looks quite promising: it successfully detects more than 90.0\% tasks. It also compares 
the result of only using NLP techniques with the result of combining NLP and program 
synthesis: without program synthesis, SmartSynth only correctly translates 58.7\% tasks. 
This result is unfair to the NLP side since the system only adopts a few light-weight 
features from it and it's not a learning-based system.

SmartSynth is not the first system on translating natural language into executable
program: SILT~\cite{silt} and WASP~\citep{wasp} translate natural language into GEO-query 
and RoboCup language; Regexp~\cite{reg} coverts natural language into regular expression.
To the best of our knowledge, we have not heard of any previous work about translating
 pseudocode(Described in an algorithm) into its implementation(C, Java or Python). 
This observation becomes the original motivation of our project.
\section{Improvement}\label{sec:alg}
The main idea of our project is to translate an algorithm(in pseudocode) into an 
executable program(Python). There are several improvements we can make based on the 
limitations of SmartSynth:

First, even though the paper claims that one of its contributions is to combine the
techniques of both NLP and program synthesis, it lacks the robustness that characterize
recent advances in statical NLP. For instance, instead of using a supervised learning 
approach to infer the dataflow relations between components, SmartSynth heavily 
relies on a set of so-called ``expert-rules" to parse the natural language. On the 
other hand, although our project will also adopt techniques from program synthesis when 
pure NLP techniques fail to cover a complete semantics of the pseudocode, we 
leverage a standard statistical model to improve the 
robustness of our system in the presence of large corpus: 
\[
f = arg \ max_{d\in D(G|s)} Pr_{\lambda}(d|s)
\]
where $s$ is the input sentence, $d$ is one possible derivation and $G$ is the 
SCFG adopted from WASP~\cite{wasp}.
We are also using a maximum-entropy model that defines the conditional probability 
over multiple derivations: given a pseudocode in natural language, the problem is reduced to searching the most probable derivation that yields the target program.


Second, SmartSynth is tightly integrating with a set of domain-specific APIs and their
corresponding English language. The consequence is to support any new API, it has to 
add new rules for the API and adjust the metrics accordingly. On the other hand, the 
context free grammar of our target language is a standard intermediate 
representation(IR) which covers most of the common semantics of the program, thus it's 
flexible to translate the IR into multiple target languages(C, Java or Python).

Third, SmartSynth only supports small task described within one 
sentence and it will be very interesting to consider the task that contains multiple 
sentences. For instance, each sample in our train set is an algorithm which is
described by multiple sentences and we need to resolve the context 
dependency~\cite{dep} between sentences when perform the semantic parsing.

Fourth, to improve the robustness of the system, even though both SmartSynth 
and our project adopt techniques from the program synthesis community, 
they focus on different aspects: while SmartSynth is using a type-directed 
completion approach~\cite{typebase} to infer the missing data flow between
the arguments and the API calls, our project tries to infer the missing 
statement based on input-output examples~\cite{input} from the user.
\subsection{Evaluation}
SmartSynth is evaluated through 50 small online tasks. Even though 
the precision sounds promising(90\%), it is still unclear how well the 
technique will be in the presence of large corpus. Especially the recall
rate is absence from their paper. As to our project of translating pseudocode to 
program, we choose 100 algorithms from both textbooks~\cite{taocp} and educational websites~\cite{codebat} and an algorithm contains about ten sentences in average. Each
pair of our training set is in the form of $(s,d)$ where $s$ is 
a sentence in the algorithm and $d$ is the meaning representation in the form 
of our formal language. Then a semantic parser is learned from the training
set through a standard 10-fold cross validation. Finally we are going to 
use the semantic parser to translate the test algorithms into the executable
codes in Python and measure its precision and recall. 
We will also plot the learning curve to study its relationship with 
the number of training set.  

One special case in our evaluation is to define a partial score for the output 
of the semantic parser, since an algorithm usually contains multiple sentences 
and it's possible that our parser fails to translate some of them. The partial
score is calculated based on the percentage of sentences that are translated
correctly.  

\subsection{Conclusion}
To conclude, both SmartSynth and our current project are targeting the problem 
of translating natural language into executable code(In our context, the pseudocode
is described by natural language and the Python program will be the target
executable code.) by combining the techniques
from both NLP and PL communities. Here is the biggest different between our 
project and SmartSynth: instead of focusing on a small specific domain
and handcrafting everything through some mysterious ``expert rules", our system
is not only designed and evaluated on top of a standard statistical model, but also leverages
the techniques(Such as inferring missing statements from input-output examples) 
from the program synthesis community to improve the robustness.

\bibliographystyle{unsrt}
\bibliography{hw4}
\end{document}
