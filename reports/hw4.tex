\documentclass[10pt]{article}
\usepackage{latexsym}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}

\title{Homework 4: Project-Related Paper Report}
\author{Yu Feng}
\date{4/20/2015}

\begin{document}
\maketitle

\section{Summary}\label{sec:intro}
Using natural language to write programs is a challenging problem for both NLP 
and PL communities. SmartSynth~\cite{smart} tackles this problem in a small domain of mobile computing. Specifically, it synthesizes smartphone automation scripts from natural language. For instance, when the user fires a task in natural language 
like the following:
\begin{quotation}
``When I receive a new SMS and I am driving, reply the sender ``I'm driving."."
\end{quotation}
the system will generate the following executable script:
\small\begin{verbatim}
when (number, content) := MessageReceived()
    if (IsConnectedToBTDevice(Car_BT) then
        SendMessage(number, "I'm driving");
\end{verbatim}
To achieve the above goal, SmartSynth's approach incorporates two key ingredients: First, it designs
a domain specific language(DSL) to bridge the gap between natural language and the
target script; Second, for the data- flow that can not be inferred by 
standard NLP techniques, SmartSynth uses techniques from the Program Synthesis community to infer the missing relations.

The paper reduces the task of generating smartphone script to weaving a set of 
related APIs. To achieve this goal, his system first identify a set of components 
through standard NLP techniques like parse tree and bag-of-words as features; 
To infer the relations among components, it adopts the rule-based technique to 
generate the relations and uses program synthesis to infer the missing ones. For
the relation that has multiple candidates, it designs a ranking scheme to pick up
the one with a highest probability.

The paper evaluates the technique through 50 online task descriptions and the result
sounds promising: the precision is over 90\%.


\section{Improvement}\label{sec:alg}
The main idea of our project is to translate an algorithm(in pseudo-code) into an 
executable program(Python). There are several improvements we can make based on the 
limitations of SmartSynth:

First, even though the paper claims that one of its contributions is to combine the
techniques of both NLP and program synthesis, it lacks the robustness that characterize
recent advances in statical NLP. For instance, instead of using a supervised learning 
approach to infer the data- flow of among multiple components, SmartSynth heavily 
relies on a set of so-called ``expert-rules" to parse the natural language. On the 
other hand, although our project will also adopt techniques from program synthesis when 
pure NLP's techniques fail to cover a complete semantics of the pseudo-code, we 
leverage a standard statistical model to improve the 
robustness of our system in the presence of large corpus: 
\[
f = arg \ max_{d\in D(G|s)} Pr_{\lambda}(d|s)
\]
where $s$ is the input sentence, $d$ is one possible derivation and $G$ is the 
SCFG adopted from WASP~\cite{wasp}.
We are also using a maximum-entropy model that defines the conditional probability 
over multiple derivations: given a pseudo-code in natural language, the problem is reduced to searching the most probable derivation that yields the target program.


Second, SmartSynth is tightly integrating with a set of domain-specific APIs and their
corresponding English language. The consequence is to support any new API, it has to 
add new rules for the API and adjusts the metrics accordingly. On the other hand, the 
context free grammar of our target language will be a standard intermediate 
representation which covers most of the common semantics of the program, thus it's 
flexible to be translated into multiple target languages(C, Java or Python).

Third, SmartSynth only supports small task described within one 
sentence and it will be very interesting to consider the task that contains multiple 
sentences. For instance, each sample of our train set is an algorithm which is
described by multiple sentences and we need to resolve the context 
dependency~\cite{dep} of them when perform the semantic parsing.

Fourth, to improve the robustness of the system, even though both SmartSynth 
and our project adopt techniques from the program synthesis community, 
they focus on different aspects: while SmartSynth is using a type-directed 
completion approach~\cite{typebase} to infer the missing data flow between
the arguments and the API calls, our project tries to infer the missing 
statement based on input-output examples~\cite{input} from the user.
\subsection{Evaluation}
SmartSynth is evaluated through 50 small online tasks. Even though 
the precision sounds promising(90\%), it is still unclear how well the 
technique will be in the presence of large corpus. Especially the recall
rate is absence from their paper. As to our project of translating pseudo-code to 
program, we choose 100 algorithms from both textbooks~\cite{taocp} and educational websites~\cite{codebat}. Each
pair of our training set is in the form of $(s,d)$ where $s$ is 
a sentence in the algorithm and $d$ is the meaning representation in the form 
of our formal language. Then a semantic parser is learned from the training
set through a standard 10-fold cross validation. Finally we are going to 
use the semantic parser to translate the test algorithms into the executable
codes in Python and measure its precision and recall. 
We will also plot the learning curve to study its relationship with 
the number of training set.  

One special case in our evaluation is to define a partial score for the output 
of the semantic parser, since an algorithm usually contains multiple sentences 
and it's possible that our parser fails to translate some of them. The partial
score is calculated based on the percentage of sentences that are translated
correctly.  

\subsection{Conclusion}
To conclude, both SmartSynth and our current project are targeting the problem 
of translating natural language into executable code(In our context, the pseudo-code
is described by natural language and the Python program will be the target
executable code.) by combining the techniques
from both NLP and PL communities. Here is the biggest different between our 
project and SmartSynth: instead of focusing on a small specific domain
and handcrafting everything through some mysterious ``expert rules", our system
is designed and evaluated on top of a standard statistical model yet leveraging
the techniques(Such as inferring missing statements from input-output examples) 
from the program synthesis community to improve the robustness.

\bibliographystyle{unsrt}
\bibliography{hw4}
\end{document}
